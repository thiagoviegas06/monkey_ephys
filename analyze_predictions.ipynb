{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Predictions Notebook\n",
    "\n",
    "Sections:\n",
    "1) Setup\n",
    "2) Load metadata and session data\n",
    "3) Load submission(s) and build prediction matrices\n",
    "4) Combine predictions with masked SBP\n",
    "5) Visualizations\n",
    "6) Compare two submissions (optional)\n",
    "7) Diagnostics / stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.rcParams['image.aspect'] = 'auto'\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    HAS_WIDGETS = True\n",
    "except Exception:\n",
    "    HAS_WIDGETS = False\n",
    "\n",
    "# User configuration\n",
    "DATA_DIR = \"kaggle_data\"\n",
    "METADATA_PATH = f\"{DATA_DIR}/metadata.csv\"\n",
    "SUBMISSION_PATHS = [\"full_window.csv\", \"adversarial.csv\"]  # one or two files\n",
    "SESSION_ID = \"S008\"\n",
    "CHANNEL = 10\n",
    "TRIAL_ID = None\n",
    "START = 0\n",
    "END = 2000\n",
    "INFER_MASK_FROM_ZERO = True\n",
    "\n",
    "print(f\"HAS_WIDGETS={HAS_WIDGETS}\")\n",
    "print(f\"DATA_DIR={DATA_DIR}\")\n",
    "print(f\"SUBMISSION_PATHS={SUBMISSION_PATHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load metadata and session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _candidate_paths(split_dir: Path, session_id: str, kind: str):\n",
    "    if kind == 'sbp':\n",
    "        return [\n",
    "            split_dir / f\"{session_id}_sbp_masked.npy\",\n",
    "            split_dir / f\"{session_id}_sbp.npy\",\n",
    "            split_dir / session_id / \"sbp_masked.npy\",\n",
    "            split_dir / session_id / \"sbp.npy\",\n",
    "        ]\n",
    "    if kind == 'kinematics':\n",
    "        return [\n",
    "            split_dir / f\"{session_id}_kinematics.npy\",\n",
    "            split_dir / session_id / \"kinematics.npy\",\n",
    "        ]\n",
    "    if kind == 'trial':\n",
    "        return [\n",
    "            split_dir / f\"{session_id}_trial_info.npz\",\n",
    "            split_dir / f\"{session_id}_trial_ids.npy\",\n",
    "            split_dir / f\"{session_id}_trials.csv\",\n",
    "            split_dir / session_id / \"trial_info.npz\",\n",
    "            split_dir / session_id / \"trial_ids.npy\",\n",
    "            split_dir / session_id / \"trials.csv\",\n",
    "        ]\n",
    "    if kind == 'mask':\n",
    "        return [\n",
    "            split_dir / f\"{session_id}_mask.npy\",\n",
    "            split_dir / session_id / \"mask.npy\",\n",
    "        ]\n",
    "    raise ValueError(f\"Unknown kind={kind}\")\n",
    "\n",
    "\n",
    "def _find_existing(candidates):\n",
    "    hit = next((p for p in candidates if p.exists()), None)\n",
    "    return hit\n",
    "\n",
    "\n",
    "def _load_trial_ids(path: Path, n_bins: int) -> np.ndarray:\n",
    "    if path.suffix == '.npz':\n",
    "        obj = np.load(path)\n",
    "        keys = set(obj.files)\n",
    "        if {'start_bins', 'end_bins'}.issubset(keys):\n",
    "            starts = obj['start_bins'].astype(np.int64)\n",
    "            ends = obj['end_bins'].astype(np.int64)\n",
    "            trial_ids = np.full((n_bins,), -1, dtype=np.int64)\n",
    "            for idx, (s, e) in enumerate(zip(starts, ends)):\n",
    "                if s < 0 or e > n_bins or e <= s:\n",
    "                    raise ValueError(f\"Invalid trial segment in {path}: start={s}, end={e}, n_bins={n_bins}\")\n",
    "                trial_ids[s:e] = idx\n",
    "            return trial_ids\n",
    "        if 'trial_ids' in keys:\n",
    "            trial_ids = obj['trial_ids'].astype(np.int64)\n",
    "            if len(trial_ids) != n_bins:\n",
    "                raise ValueError(f\"trial_ids length mismatch in {path}: {len(trial_ids)} vs {n_bins}\")\n",
    "            return trial_ids\n",
    "        raise ValueError(f\"Unsupported trial npz format in {path}. Keys={sorted(keys)}\")\n",
    "\n",
    "    if path.suffix == '.npy':\n",
    "        trial_ids = np.load(path).astype(np.int64)\n",
    "        if len(trial_ids) != n_bins:\n",
    "            raise ValueError(f\"trial_ids length mismatch in {path}: {len(trial_ids)} vs {n_bins}\")\n",
    "        return trial_ids\n",
    "\n",
    "    if path.suffix == '.csv':\n",
    "        df = pd.read_csv(path)\n",
    "        if 'trial_id' in df.columns:\n",
    "            trial_ids = df['trial_id'].to_numpy(dtype=np.int64)\n",
    "            if len(trial_ids) != n_bins:\n",
    "                raise ValueError(f\"trial_id length mismatch in {path}: {len(trial_ids)} vs {n_bins}\")\n",
    "            return trial_ids\n",
    "        if {'start_bin', 'end_bin'}.issubset(df.columns):\n",
    "            trial_ids = np.full((n_bins,), -1, dtype=np.int64)\n",
    "            for idx, row in df.reset_index(drop=True).iterrows():\n",
    "                s = int(row['start_bin'])\n",
    "                e = int(row['end_bin'])\n",
    "                if s < 0 or e > n_bins or e <= s:\n",
    "                    raise ValueError(f\"Invalid trial segment in {path}: start={s}, end={e}, n_bins={n_bins}\")\n",
    "                trial_ids[s:e] = idx\n",
    "            return trial_ids\n",
    "        raise ValueError(f\"Unsupported trial csv format in {path}. Need trial_id or start_bin/end_bin\")\n",
    "\n",
    "    raise ValueError(f\"Unsupported trial file type: {path}\")\n",
    "\n",
    "\n",
    "def load_metadata(metadata_path: str | Path) -> pd.DataFrame:\n",
    "    meta_path = Path(metadata_path)\n",
    "    if not meta_path.exists():\n",
    "        raise FileNotFoundError(f\"metadata.csv not found at {meta_path}\")\n",
    "    df = pd.read_csv(meta_path)\n",
    "    if 'session_id' not in df.columns:\n",
    "        raise ValueError(f\"metadata.csv missing session_id column. Columns: {list(df.columns)}\")\n",
    "    df['session_id'] = df['session_id'].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def resolve_split(metadata: pd.DataFrame, session_id: str, default_split: str = 'test') -> str:\n",
    "    rows = metadata.loc[metadata['session_id'] == session_id]\n",
    "    if len(rows) == 0:\n",
    "        return default_split\n",
    "    if 'split' in rows.columns:\n",
    "        split = str(rows.iloc[0]['split'])\n",
    "        if split:\n",
    "            return split\n",
    "    return default_split\n",
    "\n",
    "\n",
    "def load_session_arrays(data_dir: str | Path, metadata: pd.DataFrame, session_id: str, infer_mask_from_zero: bool = True):\n",
    "    base = Path(data_dir)\n",
    "    split = resolve_split(metadata, session_id, default_split='test')\n",
    "    split_dir = base / split\n",
    "    if not split_dir.exists():\n",
    "        raise FileNotFoundError(f\"Split directory not found: {split_dir}\")\n",
    "\n",
    "    sbp_candidates = _candidate_paths(split_dir, session_id, 'sbp')\n",
    "    kin_candidates = _candidate_paths(split_dir, session_id, 'kinematics')\n",
    "    trial_candidates = _candidate_paths(split_dir, session_id, 'trial')\n",
    "    mask_candidates = _candidate_paths(split_dir, session_id, 'mask')\n",
    "\n",
    "    sbp_path = _find_existing(sbp_candidates)\n",
    "    kin_path = _find_existing(kin_candidates)\n",
    "    trial_path = _find_existing(trial_candidates)\n",
    "    mask_path = _find_existing(mask_candidates)\n",
    "\n",
    "    if sbp_path is None:\n",
    "        searched = '\\n'.join(str(p) for p in sbp_candidates)\n",
    "        raise FileNotFoundError(f\"Missing SBP file for {session_id}. Searched:\\n{searched}\")\n",
    "    if kin_path is None:\n",
    "        searched = '\\n'.join(str(p) for p in kin_candidates)\n",
    "        raise FileNotFoundError(f\"Missing kinematics file for {session_id}. Searched:\\n{searched}\")\n",
    "    if trial_path is None:\n",
    "        searched = '\\n'.join(str(p) for p in trial_candidates)\n",
    "        raise FileNotFoundError(f\"Missing trial file for {session_id}. Searched:\\n{searched}\")\n",
    "\n",
    "    sbp = np.load(sbp_path).astype(np.float32)\n",
    "    kin = np.load(kin_path).astype(np.float32)\n",
    "    if sbp.ndim != 2 or sbp.shape[1] != 96:\n",
    "        raise ValueError(f\"Expected sbp shape (T,96), got {sbp.shape} from {sbp_path}\")\n",
    "    if kin.ndim != 2 or kin.shape[1] != 4:\n",
    "        raise ValueError(f\"Expected kinematics shape (T,4), got {kin.shape} from {kin_path}\")\n",
    "    if sbp.shape[0] != kin.shape[0]:\n",
    "        raise ValueError(f\"Length mismatch: sbp T={sbp.shape[0]} vs kin T={kin.shape[0]}\")\n",
    "\n",
    "    trial_ids = _load_trial_ids(trial_path, n_bins=sbp.shape[0])\n",
    "    if len(trial_ids) != sbp.shape[0]:\n",
    "        raise ValueError(f\"trial_ids length mismatch: {len(trial_ids)} vs T={sbp.shape[0]}\")\n",
    "\n",
    "    if mask_path is not None:\n",
    "        mask = np.load(mask_path).astype(bool)\n",
    "        if mask.shape != sbp.shape:\n",
    "            raise ValueError(f\"Mask shape mismatch: {mask.shape} vs sbp {sbp.shape} in {mask_path}\")\n",
    "    elif infer_mask_from_zero:\n",
    "        mask = (sbp == 0)\n",
    "        warnings.warn(\n",
    "            f\"Mask file not found for {session_id}. Using inferred mask from sbp==0.\",\n",
    "            stacklevel=1,\n",
    "        )\n",
    "    else:\n",
    "        searched = '\\n'.join(str(p) for p in mask_candidates)\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing mask file for {session_id} and INFER_MASK_FROM_ZERO=False. Searched:\\n{searched}\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        'session_id': session_id,\n",
    "        'split': split,\n",
    "        'sbp': sbp,\n",
    "        'kinematics': kin,\n",
    "        'trial_ids': trial_ids,\n",
    "        'mask': mask,\n",
    "        'paths': {\n",
    "            'sbp': str(sbp_path),\n",
    "            'kinematics': str(kin_path),\n",
    "            'trial_ids': str(trial_path),\n",
    "            'mask': str(mask_path) if mask_path is not None else None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "metadata = load_metadata(METADATA_PATH)\n",
    "test_ids = []\n",
    "if 'split' in metadata.columns:\n",
    "    test_ids = sorted(metadata.loc[metadata['split'] == 'test', 'session_id'].astype(str).tolist())\n",
    "\n",
    "print(f\"metadata rows={len(metadata)}\")\n",
    "print(f\"test sessions in metadata={len(test_ids)}\")\n",
    "if test_ids:\n",
    "    print(f\"first test IDs: {test_ids[:8]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Load submission(s) and build prediction matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_submission_csv(path: str | Path) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Submission file not found: {p}\")\n",
    "    df = pd.read_csv(p)\n",
    "    required = {'sample_id', 'session_id', 'time_bin', 'channel', 'predicted_sbp'}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Submission {p} missing columns: {sorted(missing)}\")\n",
    "\n",
    "    df = df[['sample_id', 'session_id', 'time_bin', 'channel', 'predicted_sbp']].copy()\n",
    "    df['session_id'] = df['session_id'].astype(str)\n",
    "    df['time_bin'] = df['time_bin'].astype(np.int64)\n",
    "    df['channel'] = df['channel'].astype(np.int64)\n",
    "    df['predicted_sbp'] = df['predicted_sbp'].astype(np.float32)\n",
    "\n",
    "    bad_ch = df[(df['channel'] < 0) | (df['channel'] > 95)]\n",
    "    if len(bad_ch) > 0:\n",
    "        raise ValueError(f\"Found {len(bad_ch)} rows with channel outside [0,95] in {p}\")\n",
    "    bad_t = df[df['time_bin'] < 0]\n",
    "    if len(bad_t) > 0:\n",
    "        raise ValueError(f\"Found {len(bad_t)} rows with negative time_bin in {p}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_prediction_matrices(df: pd.DataFrame, expected_lengths: dict[str, int] | None = None):\n",
    "    mats = {}\n",
    "    coverage = {}\n",
    "\n",
    "    for sid, grp in df.groupby('session_id', sort=True):\n",
    "        max_t = int(grp['time_bin'].max()) + 1\n",
    "        t_len = max_t\n",
    "        if expected_lengths is not None and sid in expected_lengths:\n",
    "            t_len = max(t_len, int(expected_lengths[sid]))\n",
    "\n",
    "        pred = np.full((t_len, 96), np.nan, dtype=np.float32)\n",
    "        tb = grp['time_bin'].to_numpy(dtype=np.int64)\n",
    "        ch = grp['channel'].to_numpy(dtype=np.int64)\n",
    "        vals = grp['predicted_sbp'].to_numpy(dtype=np.float32)\n",
    "\n",
    "        pred[tb, ch] = vals\n",
    "        mats[sid] = pred\n",
    "        coverage[sid] = float(np.isfinite(pred).mean())\n",
    "\n",
    "    return mats, coverage\n",
    "\n",
    "\n",
    "submission_frames = {}\n",
    "submission_mats = {}\n",
    "\n",
    "for sp in SUBMISSION_PATHS:\n",
    "    s_df = load_submission_csv(sp)\n",
    "    submission_frames[sp] = s_df\n",
    "    mats, cov = build_prediction_matrices(s_df)\n",
    "    submission_mats[sp] = mats\n",
    "    print(f\"Loaded {sp}: rows={len(s_df)}, sessions={len(mats)}, mean_coverage={np.mean(list(cov.values())):.4f}\")\n",
    "\n",
    "if len(SUBMISSION_PATHS) == 0:\n",
    "    raise ValueError(\"SUBMISSION_PATHS cannot be empty\")\n",
    "if len(SUBMISSION_PATHS) > 2:\n",
    "    warnings.warn(\"Only first two submissions will be used for pairwise comparison plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Combine predictions with masked SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_prediction_to_session(pred: np.ndarray, target_t: int) -> np.ndarray:\n",
    "    if pred.shape[1] != 96:\n",
    "        raise ValueError(f\"Prediction must be (T,96), got {pred.shape}\")\n",
    "    if pred.shape[0] == target_t:\n",
    "        return pred\n",
    "    out = np.full((target_t, 96), np.nan, dtype=np.float32)\n",
    "    t_copy = min(target_t, pred.shape[0])\n",
    "    out[:t_copy] = pred[:t_copy]\n",
    "    if pred.shape[0] != target_t:\n",
    "        warnings.warn(f\"Prediction T={pred.shape[0]} differs from session T={target_t}. Truncated/padded to match.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def fill_reconstruction(sbp: np.ndarray, mask: np.ndarray, pred: np.ndarray) -> np.ndarray:\n",
    "    if sbp.shape != mask.shape:\n",
    "        raise ValueError(f\"sbp shape {sbp.shape} != mask shape {mask.shape}\")\n",
    "    if pred.shape != sbp.shape:\n",
    "        raise ValueError(f\"pred shape {pred.shape} != sbp shape {sbp.shape}\")\n",
    "    recon = sbp.copy()\n",
    "    usable = mask & np.isfinite(pred)\n",
    "    recon[usable] = pred[usable]\n",
    "    return recon\n",
    "\n",
    "\n",
    "def _corr_safe(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    if len(x) < 2 or np.std(x) < 1e-12 or np.std(y) < 1e-12:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(x, y)[0, 1])\n",
    "\n",
    "\n",
    "def compute_stats(sbp: np.ndarray, pred: np.ndarray, mask: np.ndarray):\n",
    "    obs = ~mask\n",
    "    pred_finite = np.isfinite(pred)\n",
    "    valid_obs = obs & pred_finite\n",
    "    valid_masked = mask & pred_finite\n",
    "\n",
    "    stats = {\n",
    "        'fraction_masked': float(mask.mean()),\n",
    "        'fraction_observed': float(obs.mean()),\n",
    "        'fraction_pred_finite': float(pred_finite.mean()),\n",
    "        'fraction_masked_pred_finite': float(valid_masked.mean()),\n",
    "        'pred_masked_mean': float(np.nanmean(pred[valid_masked])) if np.any(valid_masked) else np.nan,\n",
    "        'pred_masked_std': float(np.nanstd(pred[valid_masked])) if np.any(valid_masked) else np.nan,\n",
    "    }\n",
    "\n",
    "    if np.any(valid_obs):\n",
    "        resid = pred[valid_obs] - sbp[valid_obs]\n",
    "        mse = float(np.mean(resid ** 2))\n",
    "        denom = float(np.mean((sbp[valid_obs]) ** 2))\n",
    "        nmse = mse / (denom + 1e-12)\n",
    "        corr = _corr_safe(sbp[valid_obs], pred[valid_obs])\n",
    "    else:\n",
    "        mse = np.nan\n",
    "        nmse = np.nan\n",
    "        corr = np.nan\n",
    "\n",
    "    per_channel = []\n",
    "    for c in range(96):\n",
    "        vc = valid_obs[:, c]\n",
    "        if np.any(vc):\n",
    "            rc = pred[vc, c] - sbp[vc, c]\n",
    "            mse_c = float(np.mean(rc ** 2))\n",
    "            den_c = float(np.mean((sbp[vc, c]) ** 2))\n",
    "            nmse_c = mse_c / (den_c + 1e-12)\n",
    "            corr_c = _corr_safe(sbp[vc, c], pred[vc, c])\n",
    "            n_obs = int(vc.sum())\n",
    "        else:\n",
    "            mse_c = np.nan\n",
    "            nmse_c = np.nan\n",
    "            corr_c = np.nan\n",
    "            n_obs = 0\n",
    "        per_channel.append({'channel': c, 'n_obs': n_obs, 'mse': mse_c, 'nmse': nmse_c, 'corr': corr_c})\n",
    "\n",
    "    stats['mse_observed'] = mse\n",
    "    stats['nmse_observed'] = nmse\n",
    "    stats['corr_observed'] = corr\n",
    "    stats['per_channel'] = pd.DataFrame(per_channel)\n",
    "    return stats\n",
    "\n",
    "\n",
    "session = load_session_arrays(DATA_DIR, metadata, SESSION_ID, infer_mask_from_zero=INFER_MASK_FROM_ZERO)\n",
    "print(f\"Loaded session={SESSION_ID} split={session['split']} sbp={session['sbp'].shape} kin={session['kinematics'].shape}\")\n",
    "print(f\"Paths: {session['paths']}\")\n",
    "\n",
    "analysis_by_submission = {}\n",
    "for sp in SUBMISSION_PATHS:\n",
    "    mats = submission_mats[sp]\n",
    "    if SESSION_ID not in mats:\n",
    "        raise KeyError(f\"Session {SESSION_ID} not found in submission {sp}\")\n",
    "    pred_aligned = align_prediction_to_session(mats[SESSION_ID], target_t=session['sbp'].shape[0])\n",
    "    recon = fill_reconstruction(session['sbp'], session['mask'], pred_aligned)\n",
    "    stats = compute_stats(session['sbp'], pred_aligned, session['mask'])\n",
    "    analysis_by_submission[sp] = {\n",
    "        'pred': pred_aligned,\n",
    "        'recon': recon,\n",
    "        'stats': stats,\n",
    "    }\n",
    "    print(f\"{sp}: mse_obs={stats['mse_observed']:.6f}, nmse_obs={stats['nmse_observed']:.6f}, corr_obs={stats['corr_observed']:.6f}\")\n",
    "\n",
    "# Smoke test checks\n",
    "assert session['sbp'].shape[1] == 96\n",
    "assert session['mask'].shape == session['sbp'].shape\n",
    "assert session['mask'].sum() > 0, \"No masked entries found for this session\"\n",
    "print('Smoke test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trial_boundaries(trial_ids: np.ndarray):\n",
    "    return np.where(np.diff(trial_ids) != 0)[0] + 1\n",
    "\n",
    "\n",
    "def _rolling_mean_1d(x: np.ndarray, window: int = 25) -> np.ndarray:\n",
    "    window = int(max(1, window))\n",
    "    if window <= 1:\n",
    "        return x.copy()\n",
    "    kernel = np.ones(window, dtype=np.float64) / window\n",
    "    return np.convolve(x, kernel, mode='same')\n",
    "\n",
    "\n",
    "def plot_heatmaps(session, pred, recon, title_prefix=''):\n",
    "    sbp = session['sbp']\n",
    "    mask = session['mask']\n",
    "    trial_ids = session['trial_ids']\n",
    "\n",
    "    observed_sbp = sbp.copy()\n",
    "    observed_sbp[mask] = np.nan\n",
    "    resid_obs = np.full_like(sbp, np.nan, dtype=np.float32)\n",
    "    obs = ~mask\n",
    "    resid_obs[obs] = pred[obs] - sbp[obs]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5), constrained_layout=True)\n",
    "    ims = []\n",
    "    ims.append(axes[0].imshow(observed_sbp.T, origin='lower'))\n",
    "    axes[0].set_title(f\"{title_prefix}Observed SBP (masked hidden)\")\n",
    "    ims.append(axes[1].imshow(recon.T, origin='lower'))\n",
    "    axes[1].set_title(f\"{title_prefix}Reconstruction (masked filled)\")\n",
    "    ims.append(axes[2].imshow(resid_obs.T, origin='lower', cmap='coolwarm'))\n",
    "    axes[2].set_title(f\"{title_prefix}Residual on observed (pred - observed)\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('time_bin')\n",
    "        ax.set_ylabel('channel')\n",
    "        for b in _trial_boundaries(trial_ids):\n",
    "            ax.axvline(b, color='k', lw=0.2, alpha=0.25)\n",
    "\n",
    "    for ax, im in zip(axes, ims):\n",
    "        plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_channel_series(session, pred, channel=10, start=0, end=2000, smooth_window=0, title_prefix=''):\n",
    "    sbp = session['sbp']\n",
    "    mask = session['mask']\n",
    "    T = sbp.shape[0]\n",
    "    start = int(max(0, start))\n",
    "    end = int(min(T, end))\n",
    "    if end <= start:\n",
    "        raise ValueError(f\"Invalid range start={start}, end={end}\")\n",
    "    c = int(channel)\n",
    "    if c < 0 or c > 95:\n",
    "        raise ValueError(f\"channel must be in [0,95], got {c}\")\n",
    "\n",
    "    t = np.arange(start, end)\n",
    "    obs_vals = sbp[start:end, c].copy()\n",
    "    obs_vals[mask[start:end, c]] = np.nan\n",
    "    pred_vals = pred[start:end, c]\n",
    "    pred_sm = _rolling_mean_1d(pred_vals, window=smooth_window) if smooth_window and smooth_window > 1 else None\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4), constrained_layout=True)\n",
    "    ax.plot(t, pred_vals, lw=1.0, label='predicted sbp', color='C1')\n",
    "    if pred_sm is not None:\n",
    "        ax.plot(t, pred_sm, lw=1.6, label=f'predicted smoothed (w={smooth_window})', color='C3')\n",
    "    ax.plot(t, obs_vals, lw=1.0, label='observed sbp', color='C0')\n",
    "\n",
    "    masked_t = t[mask[start:end, c]]\n",
    "    if len(masked_t) > 0:\n",
    "        ax.scatter(masked_t, pred_vals[mask[start:end, c]], s=6, alpha=0.45, color='black', label='masked locations')\n",
    "\n",
    "    ax.set_title(f\"{title_prefix}Session {session['session_id']} | channel {c}\")\n",
    "    ax.set_xlabel('time_bin')\n",
    "    ax.set_ylabel('sbp')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_distributions(session, pred, bins=80, title_prefix=''):\n",
    "    sbp = session['sbp']\n",
    "    mask = session['mask']\n",
    "    obs = ~mask\n",
    "    pred_finite = np.isfinite(pred)\n",
    "\n",
    "    masked_vals = pred[mask & pred_finite]\n",
    "    observed_vals = sbp[obs]\n",
    "    resid_obs = pred[obs & pred_finite] - sbp[obs & pred_finite]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4), constrained_layout=True)\n",
    "    axes[0].hist(observed_vals, bins=bins, alpha=0.6, label='observed entries', density=True)\n",
    "    axes[0].hist(masked_vals, bins=bins, alpha=0.6, label='predicted at masked entries', density=True)\n",
    "    axes[0].set_title(f\"{title_prefix}Value distribution\")\n",
    "    axes[0].set_xlabel('sbp')\n",
    "    axes[0].set_ylabel('density')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].hist(resid_obs, bins=bins, alpha=0.8, density=True)\n",
    "    axes[1].set_title(f\"{title_prefix}Residual distribution on observed (pred - observed)\")\n",
    "    axes[1].set_xlabel('residual')\n",
    "    axes[1].set_ylabel('density')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pick_trial_segment(trial_ids: np.ndarray, requested_trial_id=None):\n",
    "    if requested_trial_id is None:\n",
    "        valid = [int(x) for x in np.unique(trial_ids) if x >= 0]\n",
    "        if not valid:\n",
    "            raise ValueError('No non-negative trial IDs found')\n",
    "        requested_trial_id = valid[0]\n",
    "\n",
    "    idx = np.where(trial_ids == requested_trial_id)[0]\n",
    "    if len(idx) == 0:\n",
    "        raise ValueError(f\"trial_id={requested_trial_id} not present in session\")\n",
    "    return int(requested_trial_id), int(idx.min()), int(idx.max()) + 1\n",
    "\n",
    "\n",
    "def plot_trial_zoom(session, pred, channel=10, requested_trial_id=None, start=None, end=None, title_prefix=''):\n",
    "    tid, seg_start, seg_end = pick_trial_segment(session['trial_ids'], requested_trial_id)\n",
    "\n",
    "    if start is None:\n",
    "        start = seg_start\n",
    "    if end is None:\n",
    "        end = seg_end\n",
    "    start = int(max(seg_start, start))\n",
    "    end = int(min(seg_end, end))\n",
    "\n",
    "    print(f\"Using trial_id={tid}, window=[{start}, {end})\")\n",
    "    plot_channel_series(session, pred, channel=channel, start=start, end=end, smooth_window=15, title_prefix=title_prefix)\n",
    "\n",
    "    sbp = session['sbp'][start:end]\n",
    "    mask = session['mask'][start:end]\n",
    "    recon = fill_reconstruction(session['sbp'], session['mask'], pred)[start:end]\n",
    "    resid_obs = np.full_like(sbp, np.nan, dtype=np.float32)\n",
    "    obs = ~mask\n",
    "    resid_obs[obs] = pred[start:end][obs] - sbp[obs]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 4), constrained_layout=True)\n",
    "    im0 = axes[0].imshow(np.where(mask, np.nan, sbp).T, origin='lower')\n",
    "    im1 = axes[1].imshow(recon.T, origin='lower')\n",
    "    im2 = axes[2].imshow(resid_obs.T, origin='lower', cmap='coolwarm')\n",
    "    axes[0].set_title('Observed SBP (trial zoom)')\n",
    "    axes[1].set_title('Reconstruction (trial zoom)')\n",
    "    axes[2].set_title('Residual on observed (trial zoom)')\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('time_bin (zoomed)')\n",
    "        ax.set_ylabel('channel')\n",
    "    for ax, im in zip(axes, [im0, im1, im2]):\n",
    "        plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "primary_submission = SUBMISSION_PATHS[0]\n",
    "primary = analysis_by_submission[primary_submission]\n",
    "plot_heatmaps(session, primary['pred'], primary['recon'], title_prefix=f\"[{Path(primary_submission).name}] \")\n",
    "plot_channel_series(session, primary['pred'], channel=CHANNEL, start=START, end=END, smooth_window=25, title_prefix=f\"[{Path(primary_submission).name}] \")\n",
    "plot_distributions(session, primary['pred'], title_prefix=f\"[{Path(primary_submission).name}] \")\n",
    "plot_trial_zoom(session, primary['pred'], channel=CHANNEL, requested_trial_id=TRIAL_ID, start=START, end=END, title_prefix=f\"[{Path(primary_submission).name}] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Compare two submissions (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_submissions(sub_path_a: str, sub_path_b: str, data_dir: str, metadata: pd.DataFrame):\n",
    "    df_a = load_submission_csv(sub_path_a)\n",
    "    df_b = load_submission_csv(sub_path_b)\n",
    "    mats_a, _ = build_prediction_matrices(df_a)\n",
    "    mats_b, _ = build_prediction_matrices(df_b)\n",
    "\n",
    "    common = sorted(set(mats_a.keys()) & set(mats_b.keys()))\n",
    "    if not common:\n",
    "        raise ValueError('No common sessions between the two submissions')\n",
    "\n",
    "    rows = []\n",
    "    for sid in common:\n",
    "        sess = load_session_arrays(data_dir, metadata, sid, infer_mask_from_zero=INFER_MASK_FROM_ZERO)\n",
    "        pa = align_prediction_to_session(mats_a[sid], sess['sbp'].shape[0])\n",
    "        pb = align_prediction_to_session(mats_b[sid], sess['sbp'].shape[0])\n",
    "        valid = np.isfinite(pa) & np.isfinite(pb)\n",
    "        if np.any(valid):\n",
    "            diff = np.abs(pa[valid] - pb[valid])\n",
    "            mean_abs = float(np.mean(diff))\n",
    "            max_abs = float(np.max(diff))\n",
    "        else:\n",
    "            mean_abs = np.nan\n",
    "            max_abs = np.nan\n",
    "        rows.append({'session_id': sid, 'mean_abs_diff': mean_abs, 'max_abs_diff': max_abs})\n",
    "\n",
    "    cmp_df = pd.DataFrame(rows).sort_values('max_abs_diff', ascending=False)\n",
    "    return cmp_df, mats_a, mats_b\n",
    "\n",
    "\n",
    "if len(SUBMISSION_PATHS) >= 2:\n",
    "    sub_a = SUBMISSION_PATHS[0]\n",
    "    sub_b = SUBMISSION_PATHS[1]\n",
    "    cmp_df, mats_a, mats_b = compare_two_submissions(sub_a, sub_b, DATA_DIR, metadata)\n",
    "    display(cmp_df.head(15))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4), constrained_layout=True)\n",
    "    axes[0].plot(cmp_df['mean_abs_diff'].to_numpy())\n",
    "    axes[0].set_title('Mean abs diff per session')\n",
    "    axes[0].set_xlabel('session rank (sorted by max_abs_diff)')\n",
    "    axes[0].set_ylabel('mean_abs_diff')\n",
    "\n",
    "    axes[1].plot(cmp_df['max_abs_diff'].to_numpy())\n",
    "    axes[1].set_title('Max abs diff per session')\n",
    "    axes[1].set_xlabel('session rank (sorted by max_abs_diff)')\n",
    "    axes[1].set_ylabel('max_abs_diff')\n",
    "    plt.show()\n",
    "\n",
    "    if SESSION_ID in mats_a and SESSION_ID in mats_b:\n",
    "        s = load_session_arrays(DATA_DIR, metadata, SESSION_ID, infer_mask_from_zero=INFER_MASK_FROM_ZERO)\n",
    "        pa = align_prediction_to_session(mats_a[SESSION_ID], s['sbp'].shape[0])\n",
    "        pb = align_prediction_to_session(mats_b[SESSION_ID], s['sbp'].shape[0])\n",
    "        abs_diff = np.abs(pa - pb)\n",
    "        fig, ax = plt.subplots(figsize=(14, 4), constrained_layout=True)\n",
    "        im = ax.imshow(abs_diff.T, origin='lower')\n",
    "        ax.set_title(f\"Abs diff heatmap: {Path(sub_a).name} vs {Path(sub_b).name} | session {SESSION_ID}\")\n",
    "        ax.set_xlabel('time_bin')\n",
    "        ax.set_ylabel('channel')\n",
    "        for b in _trial_boundaries(s['trial_ids']):\n",
    "            ax.axvline(b, color='k', lw=0.2, alpha=0.25)\n",
    "        plt.colorbar(im, ax=ax, fraction=0.03, pad=0.02)\n",
    "        plt.show()\n",
    "else:\n",
    "    print('Only one submission provided; skipping section 6.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Diagnostics / stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sp, obj in analysis_by_submission.items():\n",
    "    print('\\n' + '=' * 80)\n",
    "    print(f\"Submission: {sp}\")\n",
    "    s = obj['stats']\n",
    "    print(f\"fraction_masked={s['fraction_masked']:.6f}\")\n",
    "    print(f\"fraction_observed={s['fraction_observed']:.6f}\")\n",
    "    print(f\"fraction_pred_finite={s['fraction_pred_finite']:.6f}\")\n",
    "    print(f\"fraction_masked_pred_finite={s['fraction_masked_pred_finite']:.6f}\")\n",
    "    print(f\"pred_masked_mean={s['pred_masked_mean']:.6f}\")\n",
    "    print(f\"pred_masked_std={s['pred_masked_std']:.6f}\")\n",
    "    print(f\"mse_observed={s['mse_observed']:.6f}\")\n",
    "    print(f\"nmse_observed={s['nmse_observed']:.6f}\")\n",
    "    print(f\"corr_observed={s['corr_observed']:.6f}\")\n",
    "\n",
    "    per_ch = s['per_channel']\n",
    "    display(per_ch.sort_values('mse', ascending=False).head(10))\n",
    "\n",
    "\n",
    "# Optional widgets for quick session/channel exploration\n",
    "if HAS_WIDGETS:\n",
    "    sid_options = sorted(set(test_ids) | {SESSION_ID})\n",
    "    sid_dd = widgets.Dropdown(options=sid_options, value=SESSION_ID, description='Session')\n",
    "    ch_slider = widgets.IntSlider(value=CHANNEL, min=0, max=95, step=1, description='Channel')\n",
    "    sub_dd = widgets.Dropdown(options=SUBMISSION_PATHS, value=SUBMISSION_PATHS[0], description='Submission')\n",
    "\n",
    "    def _update(session_id, channel, submission):\n",
    "        sess = load_session_arrays(DATA_DIR, metadata, session_id, infer_mask_from_zero=INFER_MASK_FROM_ZERO)\n",
    "        mats = submission_mats[submission]\n",
    "        if session_id not in mats:\n",
    "            print(f\"Session {session_id} not in {submission}\")\n",
    "            return\n",
    "        pred = align_prediction_to_session(mats[session_id], sess['sbp'].shape[0])\n",
    "        recon = fill_reconstruction(sess['sbp'], sess['mask'], pred)\n",
    "        plot_heatmaps(sess, pred, recon, title_prefix=f\"[{Path(submission).name}] \")\n",
    "        plot_channel_series(sess, pred, channel=channel, start=START, end=END, smooth_window=25, title_prefix=f\"[{Path(submission).name}] \")\n",
    "\n",
    "    out = widgets.interactive_output(_update, {'session_id': sid_dd, 'channel': ch_slider, 'submission': sub_dd})\n",
    "    display(widgets.HBox([sid_dd, ch_slider, sub_dd]), out)\n",
    "else:\n",
    "    print('ipywidgets not available. Edit config variables and re-run cells.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
